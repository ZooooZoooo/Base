{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 神经网络基础\n",
    "## 层和块\n",
    "如何通过继承nn.Module类来完成比较灵活的构造"
   ],
   "id": "e0d41317adf1eb07"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.526026Z",
     "start_time": "2024-07-05T03:41:44.702571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 之前多层感知机的实现\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ],
   "id": "ce177a7771c48dae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1346,  0.1856, -0.1308, -0.1414, -0.3225, -0.1797,  0.0581,  0.0773,\n",
       "          0.0930,  0.3278],\n",
       "        [-0.0444,  0.1873, -0.1892, -0.1365, -0.2767, -0.0860,  0.0562,  0.0040,\n",
       "         -0.0694,  0.3028]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.542029Z",
     "start_time": "2024-07-05T03:41:46.529026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义块\n",
    "class MLP(nn.Module):\n",
    "    # 用模型参数声明层。这里，我们声明两个全连接的层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Module的构造函数来执行必要的初始化。\n",
    "        # 这样，在类实例化时也可以指定其他函数参数。\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)  # 隐藏层\n",
    "        self.out = nn.Linear(256, 10)  # 输出层\n",
    "\n",
    "    # 定义模型的前向传播，即如何根据输入X返回所需的模型输出\n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "\n",
    "net = MLP()\n",
    "net(X)  # 实例化多层感知机的层，然后在每次调用正向传播函数时调用这些层"
   ],
   "id": "4022da659a48008",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0743, -0.0326, -0.0289,  0.1307, -0.1196,  0.0424, -0.1004, -0.0144,\n",
       "         -0.0449, -0.0581],\n",
       "        [ 0.0521,  0.0831, -0.0685,  0.1056, -0.1814, -0.0237, -0.0463, -0.1559,\n",
       "          0.1238,  0.0738]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.558011Z",
     "start_time": "2024-07-05T03:41:46.544030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 顺序块，实现两个关键函数：1、一种将块逐个追加到列表中的函数；2、一种前向传播函数，用于将输入按追加块的顺序传递给块组成的“链条”\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            # 这里，module是Module子类的一个实例。我们把它保存在'Module'类的成员\n",
    "            # 变量_modules中。_module的类型是OrderedDict\n",
    "            self._modules[str(idx)] = module\n",
    "\n",
    "    def forward(self, X):\n",
    "        # OrderedDict保证了按照成员添加的顺序遍历它们\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ],
   "id": "7afaca6437900ce0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2134, -0.0720, -0.1816,  0.0538, -0.3821, -0.2662, -0.1659,  0.1075,\n",
       "         -0.0654, -0.1311],\n",
       "        [-0.2317, -0.1468, -0.2969, -0.0065, -0.2190, -0.0877, -0.1736,  0.2565,\n",
       "         -0.1436, -0.1818]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.573261Z",
     "start_time": "2024-07-05T03:41:46.559011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 在正向传播函数中执行代码\n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 不计算梯度的随机权重参数。因此其在训练期间保持不变\n",
    "        self.rand_weight = torch.rand((20, 20), requires_grad=False)\n",
    "        self.linear = nn.Linear(20, 20)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        # 使用创建的常量参数以及relu和mm函数\n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        # 复用全连接层。这相当于两个全连接层共享参数\n",
    "        X = self.linear(X)\n",
    "        # 控制流\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "    \n",
    "net = FixedHiddenMLP()\n",
    "net(X)\n"
   ],
   "id": "f5c60c9935ee668e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0229, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.588848Z",
     "start_time": "2024-07-05T03:41:46.575450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 随意混搭\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20, 64), nn.ReLU(),\n",
    "                                 nn.Linear(64, 32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32, 16)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "\n",
    "chimera = nn.Sequential(NestMLP(), nn.Linear(16, 20), FixedHiddenMLP())\n",
    "chimera(X)"
   ],
   "id": "5545aaf828318480",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2041, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 参数管理\n",
    "访问参数、参数初始化、共享两个层的参数"
   ],
   "id": "1ddfda2384b1fcf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.604365Z",
     "start_time": "2024-07-05T03:41:46.590340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 单隐藏层的感知机\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(size=(2, 4))\n",
    "net(X)\n",
    "\n",
    "print(net[2].state_dict()) # 参数访问"
   ],
   "id": "2278842a84a5700f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('weight', tensor([[-0.0123, -0.1678, -0.1287, -0.2417,  0.2730, -0.0257,  0.1564,  0.1409]])), ('bias', tensor([-0.2929]))])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.619733Z",
     "start_time": "2024-07-05T03:41:46.606385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(type(net[2].bias)) # 第三个神经网络层提取偏置\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)"
   ],
   "id": "5bde7d6a463e971f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([-0.2929], requires_grad=True)\n",
      "tensor([-0.2929])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.635735Z",
     "start_time": "2024-07-05T03:41:46.621732Z"
    }
   },
   "cell_type": "code",
   "source": "net[2].weight.grad == None",
   "id": "edb1bb2a99072284",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.651739Z",
     "start_time": "2024-07-05T03:41:46.637736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 访问所有参数\n",
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])"
   ],
   "id": "e8c54d45723058d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.666916Z",
     "start_time": "2024-07-05T03:41:46.652860Z"
    }
   },
   "cell_type": "code",
   "source": "net.state_dict()['2.bias'].data",
   "id": "23a61c34141e6b7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2929])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.682998Z",
     "start_time": "2024-07-05T03:41:46.668023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 生成块\n",
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                         nn.Linear(8, 4), nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        # 在这里嵌套\n",
    "        net.add_module(f'block {i}', block1())\n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4, 1))\n",
    "rgnet(X)"
   ],
   "id": "b0ba1d721ce011ce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2135],\n",
       "        [-0.2136]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.698408Z",
     "start_time": "2024-07-05T03:41:46.685661Z"
    }
   },
   "cell_type": "code",
   "source": "print(rgnet) # 查看一下结构",
   "id": "928fb26ec7e141f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block 0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block 3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.714413Z",
     "start_time": "2024-07-05T03:41:46.700409Z"
    }
   },
   "cell_type": "code",
   "source": "rgnet[0][1][0].bias.data # 访问参数",
   "id": "d92d466bf40229df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3624,  0.0452, -0.1297,  0.1497, -0.2140, -0.0104,  0.1539, -0.3179])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.730416Z",
     "start_time": "2024-07-05T03:41:46.717413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_normal(m):  # 参数初始化\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ],
   "id": "c4719148cc43e2c0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0205,  0.0105, -0.0010, -0.0058]), tensor(0.))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.746306Z",
     "start_time": "2024-07-05T03:41:46.731641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def init_constant(m): # 另外一种参数初始化\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_constant)\n",
    "net[0].weight.data[0], net[0].bias.data[0]"
   ],
   "id": "9fb181a3f603375d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1.]), tensor(0.))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.762011Z",
     "start_time": "2024-07-05T03:41:46.747634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 某些块应用不同的初始化方法\n",
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "\n",
    "net[0].apply(init_xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ],
   "id": "d5cc71f3330502e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6458,  0.7050, -0.3713, -0.5682])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.777518Z",
     "start_time": "2024-07-05T03:41:46.763515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义参数初始化方法\n",
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\", *[(name, param.shape)\n",
    "                        for name, param in m.named_parameters()][0])\n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >= 5\n",
    "\n",
    "net.apply(my_init)\n",
    "net[0].weight[:2]"
   ],
   "id": "6c1956d55c63f5a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9124,  0.0000, -6.0749, -5.3296],\n",
       "        [-0.0000,  8.0262, -0.0000,  0.0000]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.792654Z",
     "start_time": "2024-07-05T03:41:46.778897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net[0].weight.data[:] += 1\n",
    "net[0].weight.data[0, 0] = 42\n",
    "net[0].weight.data[0]  # 直接设置参数的值"
   ],
   "id": "39c31603def96045",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([42.0000,  1.0000, -5.0749, -4.3296])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.808562Z",
     "start_time": "2024-07-05T03:41:46.795049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 层与层之间参数共享，首先需要定义一个共享层\n",
    "shared = nn.Linear(8, 8)\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    shared, nn.ReLU(),\n",
    "                    nn.Linear(8, 1))\n",
    "net(X)\n",
    "# 检查参数是否相同\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0, 0] = 100\n",
    "# 确保它们实际上是同一个对象，而不只是有相同的值\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ],
   "id": "1989ceef2309ae28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 自定义层",
   "id": "b3a63079035aa966"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.824005Z",
     "start_time": "2024-07-05T03:41:46.809960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 不带参数的层\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, X):\n",
    "        return X - X.mean()"
   ],
   "id": "bd8670e3f0e837fb",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.839367Z",
     "start_time": "2024-07-05T03:41:46.825005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "layer = CenteredLayer()\n",
    "layer(torch.FloatTensor([1, 2, 3, 4, 5]))   "
   ],
   "id": "8bd9dda1e947e090",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2., -1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.855489Z",
     "start_time": "2024-07-05T03:41:46.840368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net = nn.Sequential(nn.Linear(8, 128), CenteredLayer()) # 将层作为组件合并到更复杂的模型中\n",
    "Y = net(torch.rand(4, 8))\n",
    "Y.mean()"
   ],
   "id": "9594f5d76ba16f4a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.9849e-09, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.871716Z",
     "start_time": "2024-07-05T03:41:46.856489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 带参数的层，该层需要输入参数：in_units和units，分别表示输入数和输出数\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units, units))\n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "\n",
    "linear = MyLinear(5, 3)\n",
    "linear.weight"
   ],
   "id": "6242c406ec1027cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.8989, -0.5359,  0.0676],\n",
       "        [-0.9993, -0.3562, -0.6362],\n",
       "        [ 0.3141, -1.4535,  0.0708],\n",
       "        [-0.2469,  0.3079, -1.0567],\n",
       "        [-0.3581, -0.8880,  2.4030]], requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.887368Z",
     "start_time": "2024-07-05T03:41:46.873883Z"
    }
   },
   "cell_type": "code",
   "source": "linear(torch.rand(2, 5))",
   "id": "3b46d5326a99a2fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0448, 0.3533],\n",
       "        [0.0000, 0.0000, 1.0675]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.902717Z",
     "start_time": "2024-07-05T03:41:46.889369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 使用自定义层构建模型\n",
    "net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n",
    "net(torch.rand(2, 64))"
   ],
   "id": "da53301ae992726c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.2265],\n",
       "        [3.9942]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.933833Z",
     "start_time": "2024-07-05T03:41:46.904928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 读写文件，直接调用load和save函数分别读写它们\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')\n",
    "x2 = torch.load('x-file')\n",
    "x2"
   ],
   "id": "4164873021f46fce",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.965184Z",
     "start_time": "2024-07-05T03:41:46.935833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 列表存储\n",
    "y = torch.zeros(4)\n",
    "torch.save([x, y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "(x2, y2)"
   ],
   "id": "a06db9adae9c13f6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3]), tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.981097Z",
     "start_time": "2024-07-05T03:41:46.966243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 字典存储\n",
    "mydict = {'x': x, 'y': y}\n",
    "torch.save(mydict, 'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "mydict2"
   ],
   "id": "d0f58f6db5c1299a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:46.997100Z",
     "start_time": "2024-07-05T03:41:46.983097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存模型参数\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20, 256)\n",
    "        self.output = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "\n",
    "net = MLP()\n",
    "X = torch.randn(size=(2, 20))\n",
    "Y = net(X)\n",
    "torch.save(net.state_dict(), 'mlp.params')"
   ],
   "id": "1fbe9b72d562cb0e",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T03:41:47.012862Z",
     "start_time": "2024-07-05T03:41:46.998193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 恢复模型，实例化了原始多层感知机模型的一个备份\n",
    "clone = MLP()\n",
    "clone.load_state_dict(torch.load('mlp.params'))\n",
    "clone.eval()\n",
    "Y_clone = clone(X)\n",
    "Y_clone == Y"
   ],
   "id": "db9231b20719fa1b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A1",
   "language": "python",
   "name": "a1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
